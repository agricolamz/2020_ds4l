---
title: "Bayes Factor"
author: "G. Moroz"
date: "3/7/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
```


## 4. Коэффициент Байеса

### 4.1 Формула Байеса опять

Представим себе, что у нас есть $k$ гипотез $M$. Тогда формула Байеса может выглядеть вот так:

$$P(θ|Data, M_k) = \frac{P(Data|θ, M_k) \times  P(θ| M_k) }{P(Data|M_k)}$$

Коэффициент Байеса определяют как соотношение предельных правдоподобий ($P(Data, M_k)$) моделей (в принципе их может быть больше двух:

$$
BF_{12} = \frac{P(Data | M_1)}{P(Data | M_2)} 
$$

Вычислять предельные правдоподобия достаточно просто, так что порой используют численную аппроксимацию.

Рассмотрим пример эксперимента Бернулли:

* мы посчитали количество букв "а" в рассказе А. П. Чехова и получили 58 букв из рассказа длинной 699 букв (пробелы и латинские буквы выкинуты);
* представим, что у нас есть две модели, соогласно одной мы ожидаем долю 0.08, а согласно другой 0.085.

Мы помним, что эксперимент Бернулли описывается биномиальным распределением:

$$P(k | n, p) = \frac{n!}{k!(n-k)!} \times p^k \times (1-p)^{n-k} =  {n \choose k} \times p^k \times (1-p)^{n-k}$$ 

Так что в случае наших моделей будет:

$$P(Data | M_1) = {n \choose k} \times p^k \times (1-p)^{n-k} = {699 \choose 58} \times 0.08^{58} \times (1-0.08)^{699-58} = 0.0523985$$ 
```{r}
dbinom(58, 699, prob = 0.08)
```

$$P(Data | M_2) = {n \choose k} \times p^k \times (1-p)^{n-k} = {699 \choose 58} \times 0.085^{58} \times (1-0.085)^{699-58} = 0.04402509$$ 
```{r}
dbinom(58, 699, prob = 0.09)
```

Тогда коэфициент Байеса будет

```{r}
BF_12 = dbinom(58, 699, prob = 0.08)/dbinom(58, 699, prob = 0.09)
```

```{r}
tibble(x = 0:699,
       m_1 = dbinom(x, size = 699, prob = 0.08),
       m_2 = -dbinom(x, size = 699, prob = 0.09)) %>%
  gather(model, value, m_1:m_2) %>% 
  mutate(model = ifelse(x == 58, "result", model)) %>% 
  filter(x < 100) %>% 
  ggplot(aes(x, value, fill = model))+
  geom_col()
```

[Интерпретация коэффициента Байеса](https://en.wikipedia.org/wiki/Bayes_factor#Interpretation)

[В датасете c грибами](https://raw.githubusercontent.com/agricolamz/2019_BayesDan_winter/master/datasets/mushrooms.csv) (взят c [kaggle](https://www.kaggle.com/uciml/mushroom-classification)) представлено следующее распределение по месту обитания:

```{r}
df <- read_csv("https://github.com/agricolamz/2019_BayesDan_winter/blob/master/datasets/mushrooms.csv?raw=true")
df %>% 
  count(class, habitat) %>% 
  group_by(class) %>% 
  mutate(prop = n/sum(n)) %>% 
  ggplot(aes(class, prop, fill = habitat, label = round(prop, 3)))+
  geom_col()+
  geom_text(position = position_stack(vjust = 0.5), color = "white")
```

Мы нашли некоторый новый вид грибов на лужайке (`grasses`), а потом в лесу (`woods`). Давайте посчитаем $BF_{edible\ poisonous}$:


$$L(grasses,\ wood|edible) = 0.335 \times 0.447 = 0.149745$$

$$L(grasses,\ wood|poisonous) = 0.189 \times 0.324 = 0.061236$$

$$BF_{edible\ poisonous} = \frac{L(grasses,\ wood|edible)}{L(grasses,\ wood|poisonous)} = \frac{0.149745}{0.061236} = 2.445375$$

### 4.2 
Вашего друга похитили а на почту отправили [датасет](https://raw.githubusercontent.com/agricolamz/2019_BayesDan_winter/master/datasets/weather.csv), в котором записаны данные о погоде из пяти городов. Ваш телефон зазвонил, и друг сказал, что не знает куда его похитили, но за окном легкий дождь (`Rain`). А на следующий день --- сильный дождь (`Rain Thunderstorm`). Посчитайте $BH_{San\_Diego\ Auckland}$ с точностью до 1 знака после запятой.

```{r, include=FALSE}
df <- read.csv("https://raw.githubusercontent.com/agricolamz/2019_BayesDan_winter/master/datasets/weather.csv")
df %>%
  count(city, events) %>% 
  group_by(city) %>% 
  mutate(prop = n/sum(n)) %>% 
  ggplot(aes(city, prop, fill = events, label = round(prop, 3)))+
  geom_col()+
  geom_text(position = position_stack(vjust = 0.5), color = "white")

df %>%
  count(city, events) %>% 
  group_by(city) %>% 
  mutate(prop = n/sum(n)) %>% 
  select(-n) %>% 
  spread(events, prop, fill = 0) %>% 
  mutate(likelihood_r_rt = `Rain , Thunderstorm` * Rain) ->
  results

BF <- round(results$likelihood_r_rt[5]/results$likelihood_r_rt[1], 3)
```


